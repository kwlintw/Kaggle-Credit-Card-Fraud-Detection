{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous data exploration, we've conclude a few points:\n",
    "1. Data/class is extremely imbalanced\n",
    "2. The distribution of feature \"Time\" and \"Amount\" is similar between 2 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 2nd point, we can easily exclude the 2 features, or even just leave it in if we are using SVM or similar dicision boundry methods. \n",
    "For the imbalanced problem, there's a few ways to try in this scenario:\n",
    "1. Upsampling/ oversampling the class with fewer observations\n",
    "2. Downsampling the class with more observations\n",
    "3. Use weighted functions to penalize misclassification of class with fewer data\n",
    "4. Use a evaluation metric that takes class imbalance into consideration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach:\n",
    "1. Decide sampling method using a simple logistic regression method\n",
    "2. Evaluate the sampling method by F1/Recall/Precision etc.\n",
    "3. Use other more complicated algorithms to see if we can achieve better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Class  normAmount  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053      0    0.244964  \n",
       "1  0.167170  0.125895 -0.008983  0.014724      0   -0.342475  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752      0    1.160686  \n",
       "3  0.647376 -0.221929  0.062723  0.061458      0    0.140534  \n",
       "4 -0.206010  0.502292  0.219422  0.215153      0   -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df['normAmount'] = StandardScaler().fit_transform(df['Amount'].to_numpy().reshape(-1,1))\n",
    "df = df.drop(['Time','Amount'],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, df.columns != 'Class'].to_numpy(dtype=float) #data\n",
    "Y = df.iloc[:, df.columns == 'Class'].to_numpy(dtype=float) #labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start without any sampling methods to get a baseline. Simple train-test split with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.2, random_state = 0, stratify=Y)\n",
    "model = SGDClassifier(loss='log', max_iter=1000, tol=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that from now on all the \"testing\" is done in the subset of the training set, the actual test set will not be touched until we are sure of the sampling method, classification algorithm and hyper-parameter tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227845, 29)\n",
      "(227845, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "scores = cross_validate(model, X_train, Y_train.ravel(), cv=5,\n",
    "                        scoring=scoring,\n",
    "                        return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fit_time',\n",
       " 'score_time',\n",
       " 'test_accuracy',\n",
       " 'test_f1',\n",
       " 'test_precision',\n",
       " 'test_recall',\n",
       " 'train_accuracy',\n",
       " 'train_f1',\n",
       " 'train_precision',\n",
       " 'train_recall']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(scores.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99914417, 0.99910027, 0.99901249, 0.99918804, 0.9990783 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78571429, 0.86538462, 0.925     , 0.90384615, 0.875     ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['test_precision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69620253, 0.56962025, 0.46835443, 0.59493671, 0.53846154])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['test_recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73825503, 0.6870229 , 0.62184874, 0.71755725, 0.66666667])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['test_f1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results, the model actually performed not bad for a extremely skewed data in simple settings! So the features here are already pretty solid in that it provides enough information for the model to work (more or less). \n",
    "\n",
    "In this case, accuracy is pretty irrelevant. The logistic regression can achieve a pretty high precision, but the recall is pretty low.\n",
    "\n",
    "Of course, this is without parameter tuning, but the goal for this step is to set a baseline and see what we can improve. \n",
    "And since recall = TP/(TP+FN), we will perhaps try to lower the false positive rate in further down the line. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we should try other sampling methods. \n",
    "Let's start from upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that since we are over-sampling, we should create a validation set as well before doing so since the new, synthetic samples are generated from the alreay existing ones, and directly using the over-sampled set for CV comparison would not be really fair since there is a high chance of information leak in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over, X_val, Y_train_over, Y_val = train_test_split(X_train,Y_train,test_size = 0.1, random_state = 0, stratify=Y_train)\n",
    "model_over = SGDClassifier(loss='log', max_iter=1000, tol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nstar\\Anaconda2\\envs\\py37\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training before oversampling:  (205060, 29)\n",
      "size of training after oversampling :  (409410, 29)\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=1)\n",
    "X_res, Y_res = sm.fit_resample(X_train_over, Y_train_over)\n",
    "print(\"size of training before oversampling: \", X_train_over.shape)\n",
    "print(\"size of training after oversampling : \", X_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(model_over, X_res, Y_res.ravel(), cv=5,\n",
    "                        scoring=scoring,\n",
    "                        return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc:       [0.94974475 0.94761975 0.94886544 0.94512836 0.94845021]\n",
      "test precision: [0.97448848 0.97214922 0.96927988 0.9782198  0.96927717]\n",
      "test recall   : [0.92367065 0.92164334 0.92711463 0.91052979 0.92625974]\n"
     ]
    }
   ],
   "source": [
    "print(\"test acc:      \", scores['test_accuracy'])\n",
    "print(\"test precision:\", scores['test_precision'])\n",
    "print(\"test recall   :\", scores['test_recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_over.fit(X_res, Y_res)\n",
    "Y_val_pred = model_over.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision, recall, _, _ = precision_recall_fscore_support(Y_val, Y_val_pred, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.053857350800582245"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9487179487179487"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that precision is extremely low, while recall(sensitivity) is pretty high. This means:\n",
    "1. There are a lot of false positives\n",
    "2. However, the model captures most positive cases and leaves little false negatives\n",
    "\n",
    "\n",
    "Imagine deploying this model in real world. This would probabily prevent most of the credit card fraud, but may prevent a lot of normal daily usage of card holders. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try lowering the over-sampling rate, so instead of making the class hard-balanced, this time we increase the minority class for just enough portion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nstar\\Anaconda2\\envs\\py37\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training before oversampling:  (205060, 29)\n",
      "size of training after oversampling :  (225175, 29)\n",
      "precision:  0.26865671641791045\n",
      "recall:  0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=1, sampling_strategy=0.1) #sampling_strategy=float to specify ratio of minor/major\n",
    "X_res, Y_res = sm.fit_resample(X_train_over, Y_train_over)\n",
    "print(\"size of training before oversampling: \", X_train_over.shape)\n",
    "print(\"size of training after oversampling : \", X_res.shape)\n",
    "model_over_01 = SGDClassifier(loss='log', max_iter=1000, tol=1e-3)\n",
    "model_over_01.fit(X_res, Y_res)\n",
    "Y_val_pred = model_over_01.predict(X_val)\n",
    "precision, recall, _, _ = precision_recall_fscore_support(Y_val, Y_val_pred, average='binary')\n",
    "print('precision: ',precision)\n",
    "print('recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results shows that the ratio of over-sampling does effect the results. There will be a tradeoff between precision and recall if we change the ratio. \n",
    "\n",
    "In first one without specifying, the SMOTE algo over-sampled the minority class to same sample size as the majority class, so the size was doubled. This resulted in a extremely low precision but pretty high recall. \n",
    "\n",
    "In the one where ratio was set to .1, the precision was drastically increased(~.23) while recall was decreased by ~.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now let's move on to the other sampling method: down-sampling\n",
    "The imblearn package also includes a down-sampling method, but let's write one for ourselves here for practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(data, labels, ratio=1):\n",
    "    # here we assume the data is for binary classification problem\n",
    "    # the sample is choosen simply by random \n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    maj_class = unique[np.argmax(counts)]\n",
    "    mnr_class = unique[np.argmin(counts)]\n",
    "    maj_idx = np.nonzero(labels==maj_class)\n",
    "    mnr_idx = np.nonzero(labels==mnr_class)\n",
    "    rand_samp_maj = np.random.choice(maj_idx[0], (len(labels)-len(maj_idx[0]))*ratio)\n",
    "    rand_samp_data = np.concatenate((data[rand_samp_maj, :], data[mnr_idx[0],:]), axis=0)\n",
    "    rand_samp_lbl = np.concatenate((labels[rand_samp_maj, :], labels[mnr_idx[0],:]), axis=0)\n",
    "    return rand_samp_data, rand_samp_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205060, 1)\n",
      "size of training before downsampling:  (205060, 29)\n",
      "size of training after downsampling :  (710, 29)\n"
     ]
    }
   ],
   "source": [
    "X_train_down, X_val, Y_train_down, Y_val = train_test_split(X_train,Y_train,test_size = 0.1, random_state = 0, stratify=Y_train)\n",
    "X_res, Y_res = downsample(X_train_down, Y_train_down) # X_res, Y_res = \n",
    "print(\"size of training before downsampling: \", X_train_down.shape)\n",
    "print(\"size of training after downsampling : \", X_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.02238354506957048\n",
      "recall:  0.9487179487179487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nstar\\Anaconda2\\envs\\py37\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "model_down = SGDClassifier(loss='log', max_iter=1000, tol=1e-3)\n",
    "model_down.fit(X_res, Y_res)\n",
    "Y_val_pred = model_down.predict(X_val)\n",
    "precision, recall, _, _ = precision_recall_fscore_support(Y_val, Y_val_pred, average='binary')\n",
    "print('precision: ',precision)\n",
    "print('recall: ', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
